# -*- coding: utf-8 -*-
"""gemini_module

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OQC_YeKDK6yf-1jfsSh-UaPvOAjH1RLo
"""

import google.generativeai as genai
import os


# Configure API key from environment (never hardcode in production)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Model generation parameters for deterministic outputs
generation_config = {
    "temperature": 0.0,
    "top_p": 1,
    "top_k": 1,
    "max_output_tokens": 1024,
}

# Task & Action Guideline (system prompt)
TASK_GUIDELINE = (
    "You are EconoSage, a friendly and patient AI tutor specializing in economics and finance. "
    "Explain concepts and formulas clearly and simply, using examples where helpful. "
    "Be conversational and encouraging, as if tutoring a beginner. "
    "If given a computed result, explain how it was derived step-by-step without recalculating. "
    "Answer follow-up questions naturally and keep the conversation flowing."
)

# Load the Gemini model
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",  # or "gemini-pro"
    generation_config=generation_config,
)

def ask_gemini_explainer(
    user_question: str,
    computed_result: str = None,
    formula_used: str = None,
    history_session=None
) -> tuple[str, object]:
    """
    Ask Gemini a question, optionally provide a computed result and formula,
    and keep track of chat session using the Gemini SDK.

    Parameters:
    - user_question: User input
    - computed_result: Optional precomputed numeric result
    - formula_used: Optional formula string
    - history_session: An active genai.ChatSession object

    Returns:
    - Tuple of (Gemini response text, updated chat session)
    """
    try:
        if history_session is None:
            history_session = model.start_chat(history=[])
            # Inject the system-level TASK_GUIDELINE at the start
            history_session.send_message(TASK_GUIDELINE)

        if computed_result:
            full_prompt = (
                f"{user_question.strip()}\n\n"
                f"Note: The final computed result is:\n**{computed_result}**.\n"
                f"Please explain how this result was calculated"
            )
            if formula_used:
                full_prompt += f" using the formula: {formula_used}."
            full_prompt += " Provide a clear, beginner-friendly explanation."
        else:
            full_prompt = (
                f"{user_question.strip()}\n\n"
                "No precomputed result was provided. Please calculate and explain the answer fully, showing the formula and steps."
            )

        response = history_session.send_message(full_prompt)
        return response.text.strip(), history_session

    except Exception as e:
        return f"‚ùå Error from Gemini API: {str(e)}", history_session
