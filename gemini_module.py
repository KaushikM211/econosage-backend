# -*- coding: utf-8 -*-
"""gemini_module

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OQC_YeKDK6yf-1jfsSh-UaPvOAjH1RLo
"""

import google.generativeai as genai
import os

# Optionally set API key here
os.environ["GEMINI_API_KEY"] = 'AIzaSyAlWj2eG3bXiqvzo47Ts1sKo2d0EoZKKT4'

# Configure API key from environment (never hardcode in production)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Model generation parameters for deterministic outputs
generation_config = {
    "temperature": 0.0,
    "top_p": 1,
    "top_k": 1,
    "max_output_tokens": 1024,
}

# Task & Action Guideline (system prompt)
TASK_GUIDELINE = (
    "You are EconoSage, an AI tutor specialized in economics and finance. "
    "Always explain concepts, formulas, and calculation steps clearly and in beginner-friendly language. "
    "If a final computed result is provided, do NOT recalculate it yourself; instead, explain how it was derived and its meaning. "
    "If no computed result is provided, you are allowed to calculate and explain fully."
)

# Load the Gemini model
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",  # or "gemini-pro"
    generation_config=generation_config,
)

def ask_gemini_explainer(
    user_question: str,
    computed_result: str = None,
    formula_used: str = None,
    history_session=None
) -> tuple[str, object]:
    """
    Ask Gemini a question, optionally provide a computed result and formula,
    and keep track of chat session using the Gemini SDK.

    Parameters:
    - user_question: User input
    - computed_result: Optional precomputed numeric result
    - formula_used: Optional formula string
    - history_session: An active genai.ChatSession object

    Returns:
    - Tuple of (Gemini response text, updated chat session)
    """
    try:
        if history_session is None:
            history_session = model.start_chat(history=[])
            # Inject the system-level TASK_GUIDELINE at the start
            history_session.send_message(TASK_GUIDELINE)

        if computed_result:
            full_prompt = (
                f"{user_question.strip()}\n\n"
                f"Note: The final computed result is:\n**{computed_result}**.\n"
                f"Please explain how this result was calculated"
            )
            if formula_used:
                full_prompt += f" using the formula: {formula_used}."
            full_prompt += " Provide a clear, beginner-friendly explanation."
        else:
            full_prompt = (
                f"{user_question.strip()}\n\n"
                "No precomputed result was provided. Please calculate and explain the answer fully, showing the formula and steps."
            )

        response = history_session.send_message(full_prompt)
        return response.text.strip(), history_session

    except Exception as e:
        return f"‚ùå Error from Gemini API: {str(e)}", history_session
